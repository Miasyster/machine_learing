#!/usr/bin/env python3
"""
æ—¶é—´åºåˆ—è®­ç»ƒç¤ºä¾‹è„šæœ¬
å±•ç¤ºå®Œæ•´çš„æ—¶é—´åºåˆ—æ•°æ®åˆ’åˆ†ã€äº¤å‰éªŒè¯å’ŒWalk-forwardéªŒè¯æµç¨‹
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ¨¡å‹
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# å¯¼å…¥æˆ‘ä»¬çš„è®­ç»ƒæ¨¡å—
from src.training.time_series_trainer import TimeSeriesTrainer, TimeSeriesTrainingConfig
from src.training.time_series_validation import TimeSeriesConfig


def generate_time_series_data(n_samples=1000, n_features=5, noise_level=0.1):
    """ç”Ÿæˆæ¨¡æ‹Ÿæ—¶é—´åºåˆ—æ•°æ®"""
    print("ğŸ“Š ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®...")
    
    # åˆ›å»ºæ—¶é—´ç´¢å¼•
    start_date = datetime(2020, 1, 1)
    dates = [start_date + timedelta(days=i) for i in range(n_samples)]
    
    # ç”Ÿæˆç‰¹å¾
    np.random.seed(42)
    
    # è¶‹åŠ¿ç‰¹å¾
    trend = np.linspace(0, 10, n_samples)
    
    # å­£èŠ‚æ€§ç‰¹å¾
    seasonal = 2 * np.sin(2 * np.pi * np.arange(n_samples) / 365.25)
    
    # éšæœºç‰¹å¾
    random_features = np.random.randn(n_samples, n_features-2)
    
    # ç»„åˆç‰¹å¾
    X = np.column_stack([
        trend,
        seasonal,
        *[random_features[:, i] for i in range(n_features-2)]
    ])
    
    # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆå¸¦æœ‰æ—¶é—´ä¾èµ–æ€§ï¼‰
    y = (
        2 * trend +
        1.5 * seasonal +
        0.5 * np.sum(random_features, axis=1) +
        noise_level * np.random.randn(n_samples)
    )
    
    # æ·»åŠ ä¸€äº›æ—¶é—´ä¾èµ–æ€§
    for i in range(1, n_samples):
        y[i] += 0.1 * y[i-1]
    
    # åˆ›å»ºDataFrame
    feature_names = ['trend', 'seasonal'] + [f'feature_{i}' for i in range(n_features-2)]
    df = pd.DataFrame(X, columns=feature_names, index=dates)
    df['target'] = y
    
    print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ: {df.shape}")
    print(f"   æ—¶é—´èŒƒå›´: {dates[0].strftime('%Y-%m-%d')} åˆ° {dates[-1].strftime('%Y-%m-%d')}")
    
    return df


def create_models():
    """åˆ›å»ºæ¨¡å‹å­—å…¸"""
    print("ğŸ¤– åˆ›å»ºæ¨¡å‹...")
    
    models = {
        'linear': LinearRegression(),
        'ridge': Ridge(alpha=1.0),
        'lasso': Lasso(alpha=1.0),
        'random_forest': RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        ),
        'gradient_boosting': GradientBoostingRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        ),
        'svr': SVR(kernel='rbf', C=1.0, gamma='scale')
    }
    
    print(f"âœ… åˆ›å»ºäº† {len(models)} ä¸ªæ¨¡å‹")
    return models


def run_basic_training(df, models):
    """è¿è¡ŒåŸºç¡€è®­ç»ƒ"""
    print("\n" + "="*60)
    print("ğŸ‹ï¸ åŸºç¡€æ—¶é—´åºåˆ—è®­ç»ƒ")
    print("="*60)
    
    # å‡†å¤‡æ•°æ®
    X = df.drop('target', axis=1).values
    y = df['target'].values
    
    # é…ç½®è®­ç»ƒå‚æ•°
    ts_config = TimeSeriesConfig(
        train_ratio=0.6,
        val_ratio=0.2,
        test_ratio=0.2,
        gap=0  # æ— é—´éš”
    )
    
    training_config = TimeSeriesTrainingConfig(
        time_series_config=ts_config,
        verbose=True,
        random_state=42
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = TimeSeriesTrainer(config=training_config, models=models)
    
    # è®­ç»ƒæ¨¡å‹
    trainer.fit(X, y)
    
    # æ˜¾ç¤ºç»“æœ
    print("\nğŸ“ˆ è®­ç»ƒç»“æœ:")
    comparison = trainer.get_model_comparison()
    print(comparison)
    
    return trainer


def run_cross_validation(df, models):
    """è¿è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯"""
    print("\n" + "="*60)
    print("ğŸ”„ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯")
    print("="*60)
    
    # å‡†å¤‡æ•°æ®
    X = df.drop('target', axis=1).values
    y = df['target'].values
    
    # é…ç½®äº¤å‰éªŒè¯
    ts_config = TimeSeriesConfig(
        train_ratio=0.6,
        val_ratio=0.2,
        test_ratio=0.2,
        gap=5  # 5å¤©é—´éš”
    )
    
    training_config = TimeSeriesTrainingConfig(
        time_series_config=ts_config,
        use_time_series_cv=True,
        cv_folds=5,
        verbose=True,
        random_state=42
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = TimeSeriesTrainer(config=training_config, models=models)
    
    # è®­ç»ƒæ¨¡å‹
    trainer.fit(X, y)
    
    # æ˜¾ç¤ºäº¤å‰éªŒè¯ç»“æœï¼ˆå·²åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰§è¡Œï¼‰
    print("\nğŸ“Š äº¤å‰éªŒè¯ç»“æœ:")
    comparison = trainer.get_model_comparison()
    if 'cv_mean_r2' in comparison.columns:
        for _, row in comparison.iterrows():
            model_name = row['model']
            cv_mean = row.get('cv_mean_r2', 'N/A')
            cv_std = row.get('cv_std_r2', 'N/A')
            if isinstance(cv_mean, (int, float)) and isinstance(cv_std, (int, float)):
                print(f"{model_name:15} | RÂ² = {cv_mean:.3f} Â± {cv_std:.3f}")
            else:
                print(f"{model_name:15} | RÂ² = {cv_mean} Â± {cv_std}")
    
    # æ„é€ cv_resultsç”¨äºè¿”å›
    cv_results = {}
    if 'cv_mean_r2' in comparison.columns:
        for _, row in comparison.iterrows():
            model_name = row['model']
            cv_mean = row.get('cv_mean_r2', 0)
            cv_std = row.get('cv_std_r2', 0)
            if isinstance(cv_mean, (int, float)):
                # æ¨¡æ‹Ÿäº¤å‰éªŒè¯åˆ†æ•°
                cv_results[model_name] = [cv_mean] * 5
    
    return trainer, cv_results


def run_walk_forward_validation(df, models):
    """è¿è¡ŒWalk-forwardéªŒè¯"""
    print("\n" + "="*60)
    print("ğŸš¶ Walk-Forward éªŒè¯")
    print("="*60)
    
    # å‡†å¤‡æ•°æ®
    X = df.drop('target', axis=1).values
    y = df['target'].values
    
    # é…ç½®Walk-forwardéªŒè¯
    ts_config = TimeSeriesConfig(
        train_ratio=0.6,
        val_ratio=0.2,
        test_ratio=0.2,
        gap=10  # 10å¤©é—´éš”
    )
    
    training_config = TimeSeriesTrainingConfig(
        time_series_config=ts_config,
        use_walk_forward=True,
        verbose=True,
        random_state=42
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = TimeSeriesTrainer(config=training_config, models=models)
    
    # è®­ç»ƒæ¨¡å‹
    trainer.fit(X, y)
    
    # æ˜¾ç¤ºWalk-forwardéªŒè¯ç»“æœï¼ˆå·²åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰§è¡Œï¼‰
    print("\nğŸ“Š Walk-forwardéªŒè¯ç»“æœ:")
    comparison = trainer.get_model_comparison()
    if 'wf_mean_score' in comparison.columns:
        for _, row in comparison.iterrows():
            model_name = row['model']
            wf_mean = row.get('wf_mean_score', 'N/A')
            wf_std = row.get('wf_std_score', 'N/A')
            if isinstance(wf_mean, (int, float)) and isinstance(wf_std, (int, float)):
                print(f"{model_name:15} | RÂ² = {wf_mean:.3f} Â± {wf_std:.3f}")
            else:
                print(f"{model_name:15} | RÂ² = {wf_mean} Â± {wf_std}")
    
    # æ„é€ wf_resultsç”¨äºè¿”å›
    wf_results = {}
    if 'wf_mean_score' in comparison.columns:
        for _, row in comparison.iterrows():
            model_name = row['model']
            wf_mean = row.get('wf_mean_score', 0)
            wf_std = row.get('wf_std_score', 0)
            if isinstance(wf_mean, (int, float)):
                # æ¨¡æ‹Ÿwalk-forwardåˆ†æ•°
                wf_results[model_name] = [wf_mean] * 5
    
    return trainer, wf_results


def visualize_results(df, trainer, cv_results, wf_results):
    """å¯è§†åŒ–ç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“Š ç»“æœå¯è§†åŒ–")
    print("="*60)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œè´Ÿå·æ˜¾ç¤º
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    # è®¾ç½®å­—ä½“å¤§å°
    plt.rcParams['font.size'] = 10
    
    # è®¾ç½®å›¾å½¢æ ·å¼
    plt.style.use('seaborn-v0_8')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. æ—¶é—´åºåˆ—æ•°æ®
    axes[0, 0].plot(df.index, df['target'], alpha=0.7)
    axes[0, 0].set_title('æ—¶é—´åºåˆ—æ•°æ®')
    axes[0, 0].set_xlabel('æ—¶é—´')
    axes[0, 0].set_ylabel('ç›®æ ‡å€¼')
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ
    comparison = trainer.get_model_comparison()
    if 'test_r2' in comparison.columns:
        comparison.plot(x='model', y='test_r2', kind='bar', ax=axes[0, 1])
        axes[0, 1].set_title('æ¨¡å‹R2æ€§èƒ½æ¯”è¾ƒ')
        axes[0, 1].set_ylabel('R2 Score')
        axes[0, 1].tick_params(axis='x', rotation=45)
        # è®¾ç½®Yè½´èŒƒå›´ä»¥æ­£ç¡®æ˜¾ç¤ºè´Ÿå€¼
        min_r2 = comparison['test_r2'].min()
        max_r2 = comparison['test_r2'].max()
        y_margin = (max_r2 - min_r2) * 0.1
        axes[0, 1].set_ylim(min_r2 - y_margin, max_r2 + y_margin)
        axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
        axes[0, 1].grid(True, alpha=0.3)
    
    # 3. äº¤å‰éªŒè¯ç»“æœ
    if cv_results:
        cv_means = [np.mean(scores) for scores in cv_results.values()]
        cv_stds = [np.std(scores) for scores in cv_results.values()]
        model_names = list(cv_results.keys())
        
        axes[1, 0].bar(model_names, cv_means, yerr=cv_stds, capsize=5)
        axes[1, 0].set_title('äº¤å‰éªŒè¯ç»“æœ')
        axes[1, 0].set_ylabel('R2 Score')
        axes[1, 0].tick_params(axis='x', rotation=45)
        # è®¾ç½®Yè½´èŒƒå›´ä»¥æ­£ç¡®æ˜¾ç¤ºè´Ÿå€¼
        min_cv = min(cv_means) - max(cv_stds)
        max_cv = max(cv_means) + max(cv_stds)
        y_margin = (max_cv - min_cv) * 0.1
        axes[1, 0].set_ylim(min_cv - y_margin, max_cv + y_margin)
        axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)
        axes[1, 0].grid(True, alpha=0.3)
    
    # 4. Walk-forwardéªŒè¯ç»“æœ
    if wf_results:
        wf_means = [np.mean(scores) for scores in wf_results.values()]
        wf_stds = [np.std(scores) for scores in wf_results.values()]
        model_names = list(wf_results.keys())
        
        axes[1, 1].bar(model_names, wf_means, yerr=wf_stds, capsize=5)
        axes[1, 1].set_title('Walk-ForwardéªŒè¯ç»“æœ')
        axes[1, 1].set_ylabel('R2 Score')
        axes[1, 1].tick_params(axis='x', rotation=45)
        # è®¾ç½®Yè½´èŒƒå›´ä»¥æ­£ç¡®æ˜¾ç¤ºè´Ÿå€¼
        min_wf = min(wf_means) - max(wf_stds)
        max_wf = max(wf_means) + max(wf_stds)
        y_margin = (max_wf - min_wf) * 0.1
        axes[1, 1].set_ylim(min_wf - y_margin, max_wf + y_margin)
        axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
        axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('time_series_training_results.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š ç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º 'time_series_training_results.png'")
    
    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ—¶é—´åºåˆ—è®­ç»ƒå®Œæ•´ç¤ºä¾‹")
    print("="*60)
    
    # 1. ç”Ÿæˆæ•°æ®
    df = generate_time_series_data(n_samples=1000, n_features=5)
    
    # 2. åˆ›å»ºæ¨¡å‹
    models = create_models()
    
    # 3. åŸºç¡€è®­ç»ƒ
    basic_trainer = run_basic_training(df, models)
    
    # 4. äº¤å‰éªŒè¯
    cv_trainer, cv_results = run_cross_validation(df, models)
    
    # 5. Walk-forwardéªŒè¯
    wf_trainer, wf_results = run_walk_forward_validation(df, models)
    
    # 6. å¯è§†åŒ–ç»“æœ
    try:
        visualize_results(df, basic_trainer, cv_results, wf_results)
    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å®‰è£…äº†matplotlibå’Œseaborn")
    
    # 7. æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“‹ è®­ç»ƒæ€»ç»“")
    print("="*60)
    
    print("âœ… å®Œæˆçš„ä»»åŠ¡:")
    print("   - æ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆ")
    print("   - åŸºç¡€æ—¶é—´åºåˆ—è®­ç»ƒ")
    print("   - æ—¶é—´åºåˆ—äº¤å‰éªŒè¯")
    print("   - Walk-forwardéªŒè¯")
    print("   - ç»“æœå¯è§†åŒ–")
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {basic_trainer.get_best_model_name()}")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("   - å°è¯•æ›´å¤šæ¨¡å‹ç±»å‹")
    print("   - è°ƒæ•´éªŒè¯å‚æ•°")
    print("   - æ·»åŠ ç‰¹å¾å·¥ç¨‹")
    print("   - å®æ–½æ¨¡å‹é›†æˆ")
    
    return basic_trainer, cv_trainer, wf_trainer


if __name__ == "__main__":
    trainer_basic, trainer_cv, trainer_wf = main()